{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the reviews we have scrap and left only the content column\n",
    "df = pd.read_csv('reviews_ingles.csv')\n",
    "df = df.drop([\"Review\", \"Title\",\"Content\"], axis=1)\n",
    "df = df.dropna(subset=['reviews_english'])\n",
    "df['reviews_english'] = df['reviews_english'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    '''a function for preprocess the text: token, lemmas, stopwords'''\n",
    "    # Step 1: Convert to lowercase and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Step 2: Remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Step 3: remove punctuation\n",
    "    list_no_punctuation = [re.sub(r'['+string.punctuation+']+', ' ', i) for i in filtered_tokens]\n",
    "    \n",
    "    # Step 4: Lemmatize each token (FIXED: using 'token' instead of 'tokens')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in list_no_punctuation]\n",
    "    \n",
    "    # Step 5: Join back into a string\n",
    "    processed_text = \" \".join(lemmatized_tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recommend  s super tasty   also good  s gluten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>better protein bar   completely satisfied orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar taste great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tasty üòç 10 10 ‚úåÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>totally worth     delicious   say    s awesome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>super tasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ideal go   top consistency   taste 1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>top tasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>perfect energy kick little sweetness enough pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>perfect protein bar   without extreme sweetnes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reviews_english\n",
       "0    recommend  s super tasty   also good  s gluten...\n",
       "1    better protein bar   completely satisfied orde...\n",
       "2                                    bar taste great  \n",
       "3                                     tasty üòç 10 10 ‚úåÔ∏è\n",
       "4    totally worth     delicious   say    s awesome...\n",
       "..                                                 ...\n",
       "123                                        super tasty\n",
       "124            ideal go   top consistency   taste 1a  \n",
       "125                                          top tasty\n",
       "126  perfect energy kick little sweetness enough pr...\n",
       "127  perfect protein bar   without extreme sweetnes...\n",
       "\n",
       "[125 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_english'] = df['reviews_english'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noew let's analyze the sentiment of the words\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "'''this way we will obtain a dictionary with four keys: neg, neu, pos, and compound'''\n",
    "# neg = negative sentiment score (between 0 and 1)\n",
    "# neu = neutral sentiment score (between 0 and 1)\n",
    "# pos = positive sentiment score (between 0 and 1)\n",
    "# compound = overall sentiment (between -1 and 1)\n",
    "def get_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_english</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recommend  s super tasty   also good  s gluten...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>better protein bar   completely satisfied orde...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.7178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar taste great</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tasty üòç 10 10 ‚úåÔ∏è</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>totally worth     delicious   say    s awesome...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>super tasty</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ideal go   top consistency   taste 1a</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>top tasty</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>perfect energy kick little sweetness enough pr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.8598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>perfect protein bar   without extreme sweetnes...</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.3261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reviews_english    neg    neu    pos  \\\n",
       "0    recommend  s super tasty   also good  s gluten...  0.000  0.340  0.660   \n",
       "1    better protein bar   completely satisfied orde...  0.000  0.500  0.500   \n",
       "2                                    bar taste great    0.000  0.328  0.672   \n",
       "3                                     tasty üòç 10 10 ‚úåÔ∏è  0.000  1.000  0.000   \n",
       "4    totally worth     delicious   say    s awesome...  0.000  0.301  0.699   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "123                                        super tasty  0.000  0.204  0.796   \n",
       "124            ideal go   top consistency   taste 1a    0.000  0.435  0.565   \n",
       "125                                          top tasty  0.000  0.357  0.643   \n",
       "126  perfect energy kick little sweetness enough pr...  0.000  0.487  0.513   \n",
       "127  perfect protein bar   without extreme sweetnes...  0.298  0.319  0.383   \n",
       "\n",
       "     compound  \n",
       "0      0.9382  \n",
       "1      0.7178  \n",
       "2      0.6249  \n",
       "3      0.0000  \n",
       "4      0.9616  \n",
       "..        ...  \n",
       "123    0.5994  \n",
       "124    0.6369  \n",
       "125    0.2023  \n",
       "126    0.8598  \n",
       "127    0.3261  \n",
       "\n",
       "[125 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"] = df[\"reviews_english\"].apply(get_sentiment)\n",
    "df = pd.concat([\n",
    "    df.drop(\"sentiment\", axis=1),\n",
    "    df[\"sentiment\"].apply(pd.Series)\n",
    "], axis = 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sentiment_analysis_scores.csv\", sep= \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 125\n",
      "Positive reviews: 111 (88.8%)\n",
      "Negative reviews: 3 (2.4%)\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics with proper f-strings\n",
    "print(f\"Total reviews: {len(df)}\")\n",
    "print(f\"Positive reviews: {len(df[df['compound'] > 0])} ({(len(df[df['compound'] > 0])/len(df)*100):.1f}%)\")\n",
    "print(f\"Negative reviews: {len(df[df['compound'] < 0])} ({(len(df[df['compound'] < 0])/len(df)*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter positive/negative reviews\n",
    "positive_text = \" \".join(df[df['compound'] > 0]['reviews_english'])\n",
    "negative_text = \" \".join(df[df['compound'] < 0]['reviews_english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds\n",
    "wordcloud_pos = WordCloud(width=800, height=400, background_color='white').generate(positive_text)\n",
    "# wordcloud_neg = WordCloud(width=800, height=400, background_color='black').generate(negative_text)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Positive word cloud\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_pos, interpolation='bilinear')\n",
    "plt.title('Positive Reviews', fontsize=14, pad=20)  # Fixed title formatting\n",
    "plt.axis('off')\n",
    "\n",
    "# Negative word cloud\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(wordcloud_neg, interpolation='bilinear')\n",
    "# plt.title('Negative Reviews', fontsize=14, pad=20)  # Fixed title formatting\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter positive/negative reviews\n",
    "positive_texts = df[df['compound'] > 0]['reviews_english'].tolist()\n",
    "negative_texts = df[df['compound'] < 0]['reviews_english'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all documents but mark their class\n",
    "documents = positive_texts + negative_texts\n",
    "labels = ['positive'] * len(positive_texts) + ['negative'] * len(negative_texts)\n",
    "\n",
    "# Compute TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Create a DataFrame of TF-IDF scores\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "tfidf_df['sentiment'] = labels  # Add labels for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by sentiment and get top words\n",
    "top_words_by_sentiment = {\n",
    "    sentiment: tfidf_df[tfidf_df['sentiment'] == sentiment]\n",
    "              .drop(columns='sentiment')\n",
    "              .mean()\n",
    "              .nlargest(50)\n",
    "    for sentiment in ['positive', 'negative']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': taste          0.092687\n",
       " good           0.087782\n",
       " bar            0.080717\n",
       " tasty          0.071256\n",
       " delicious      0.068881\n",
       " great          0.063753\n",
       " super          0.047377\n",
       " consistency    0.045710\n",
       " really         0.043338\n",
       " sweet          0.037359\n",
       " protein        0.036014\n",
       " value          0.035295\n",
       " like           0.033326\n",
       " perfect        0.031651\n",
       " bit            0.030217\n",
       " snack          0.029081\n",
       " nutritional    0.028953\n",
       " ideal          0.022738\n",
       " training       0.022471\n",
       " best           0.021625\n",
       " filling        0.019747\n",
       " ingredient     0.018789\n",
       " berry          0.017300\n",
       " hard           0.017013\n",
       " energy         0.016937\n",
       " natural        0.016906\n",
       " gym            0.015942\n",
       " right          0.015852\n",
       " recommend      0.015751\n",
       " goat           0.015665\n",
       " meal           0.014940\n",
       " workout        0.014724\n",
       " little         0.014267\n",
       " provides       0.013923\n",
       " yummy          0.013310\n",
       " satisfied      0.013236\n",
       " dry            0.013176\n",
       " smaak          0.012670\n",
       " chew           0.012449\n",
       " fruity         0.012424\n",
       " chocolate      0.012410\n",
       " sticky         0.012298\n",
       " pre            0.011578\n",
       " nice           0.011298\n",
       " soft           0.011129\n",
       " simply         0.010998\n",
       " long           0.010946\n",
       " breakfast      0.010828\n",
       " exactly        0.010724\n",
       " better         0.010020\n",
       " dtype: float64,\n",
       " 'negative': version          0.197173\n",
       " firm             0.191829\n",
       " unfortunately    0.191829\n",
       " ai               0.167475\n",
       " sticky           0.163211\n",
       " tasty            0.104291\n",
       " beaucoup         0.083738\n",
       " gout             0.083738\n",
       " instant          0.083738\n",
       " pa               0.083738\n",
       " pour             0.083738\n",
       " present          0.083738\n",
       " pris             0.083738\n",
       " sucre            0.083738\n",
       " test√©            0.083738\n",
       " tout             0.083738\n",
       " √©chantillons     0.083738\n",
       " je               0.077017\n",
       " 1st              0.071460\n",
       " breaking         0.071460\n",
       " deserves         0.071460\n",
       " edited           0.071460\n",
       " latch            0.071460\n",
       " longer           0.071460\n",
       " manner           0.071460\n",
       " relaxed          0.071460\n",
       " stuck            0.071460\n",
       " tooth            0.071460\n",
       " worry            0.071460\n",
       " compared         0.065724\n",
       " eat              0.061655\n",
       " new              0.058498\n",
       " bar              0.054835\n",
       " really           0.038889\n",
       " 10               0.000000\n",
       " 1a               0.000000\n",
       " absolute         0.000000\n",
       " absolutely       0.000000\n",
       " accompaniment    0.000000\n",
       " addition         0.000000\n",
       " alternative      0.000000\n",
       " amazing          0.000000\n",
       " annoys           0.000000\n",
       " answer           0.000000\n",
       " anymore          0.000000\n",
       " appealing        0.000000\n",
       " available        0.000000\n",
       " awesome          0.000000\n",
       " backpack         0.000000\n",
       " bad              0.000000\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_by_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî† Top 20 POSITIVE Words (TF-IDF Scores):\n",
      "+-------------+----------------+\n",
      "|             |   TF-IDF Score |\n",
      "+=============+================+\n",
      "| taste       |          0.093 |\n",
      "+-------------+----------------+\n",
      "| good        |          0.088 |\n",
      "+-------------+----------------+\n",
      "| bar         |          0.081 |\n",
      "+-------------+----------------+\n",
      "| tasty       |          0.071 |\n",
      "+-------------+----------------+\n",
      "| delicious   |          0.069 |\n",
      "+-------------+----------------+\n",
      "| great       |          0.064 |\n",
      "+-------------+----------------+\n",
      "| super       |          0.047 |\n",
      "+-------------+----------------+\n",
      "| consistency |          0.046 |\n",
      "+-------------+----------------+\n",
      "| really      |          0.043 |\n",
      "+-------------+----------------+\n",
      "| sweet       |          0.037 |\n",
      "+-------------+----------------+\n",
      "| protein     |          0.036 |\n",
      "+-------------+----------------+\n",
      "| value       |          0.035 |\n",
      "+-------------+----------------+\n",
      "| like        |          0.033 |\n",
      "+-------------+----------------+\n",
      "| perfect     |          0.032 |\n",
      "+-------------+----------------+\n",
      "| bit         |          0.030 |\n",
      "+-------------+----------------+\n",
      "| snack       |          0.029 |\n",
      "+-------------+----------------+\n",
      "| nutritional |          0.029 |\n",
      "+-------------+----------------+\n",
      "| ideal       |          0.023 |\n",
      "+-------------+----------------+\n",
      "| training    |          0.022 |\n",
      "+-------------+----------------+\n",
      "| best        |          0.022 |\n",
      "+-------------+----------------+\n",
      "\n",
      "üî† Top 20 NEGATIVE Words (TF-IDF Scores):\n",
      "+---------------+----------------+\n",
      "|               |   TF-IDF Score |\n",
      "+===============+================+\n",
      "| version       |          0.197 |\n",
      "+---------------+----------------+\n",
      "| firm          |          0.192 |\n",
      "+---------------+----------------+\n",
      "| unfortunately |          0.192 |\n",
      "+---------------+----------------+\n",
      "| ai            |          0.167 |\n",
      "+---------------+----------------+\n",
      "| sticky        |          0.163 |\n",
      "+---------------+----------------+\n",
      "| tasty         |          0.104 |\n",
      "+---------------+----------------+\n",
      "| beaucoup      |          0.084 |\n",
      "+---------------+----------------+\n",
      "| gout          |          0.084 |\n",
      "+---------------+----------------+\n",
      "| instant       |          0.084 |\n",
      "+---------------+----------------+\n",
      "| pa            |          0.084 |\n",
      "+---------------+----------------+\n",
      "| pour          |          0.084 |\n",
      "+---------------+----------------+\n",
      "| present       |          0.084 |\n",
      "+---------------+----------------+\n",
      "| pris          |          0.084 |\n",
      "+---------------+----------------+\n",
      "| sucre         |          0.084 |\n",
      "+---------------+----------------+\n",
      "| test√©         |          0.084 |\n",
      "+---------------+----------------+\n",
      "| tout          |          0.084 |\n",
      "+---------------+----------------+\n",
      "| √©chantillons  |          0.084 |\n",
      "+---------------+----------------+\n",
      "| je            |          0.077 |\n",
      "+---------------+----------------+\n",
      "| 1st           |          0.071 |\n",
      "+---------------+----------------+\n",
      "| breaking      |          0.071 |\n",
      "+---------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame and print\n",
    "for sentiment, word_scores in top_words_by_sentiment.items():\n",
    "    print(f\"\\nüî† Top 20 {sentiment.upper()} Words (TF-IDF Scores):\")\n",
    "    print(\n",
    "        pd.DataFrame(word_scores.nlargest(20),  # Show top 20 words\n",
    "        columns=['TF-IDF Score']\n",
    "    ).to_markdown(tablefmt=\"grid\", floatfmt=\".3f\"))  # Grid format with 3 decimal places"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
